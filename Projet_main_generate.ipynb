{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoltanReza/classification/blob/main/Projet_main_generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XevyK73LWpS3"
      },
      "source": [
        "#Prérequis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ox0BXqzFtJx5"
      },
      "outputs": [],
      "source": [
        "# pour monter son drive Google Drive local\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
        "# Ajout du path pour les librairies, fonctions et données\n",
        "sys.path.append(my_local_drive)\n",
        "# Se positionner sur le répertoire associé\n",
        "%cd $my_local_drive\n",
        "\n",
        "%pwd\n",
        "\n",
        "\n",
        "!pip install umap-learn[plot]\n",
        "!pip install holoviews\n",
        "!pip install  ipykernel\n",
        "!pip install joblib\n",
        "!pip install scikeras\n",
        "!pip install scikit-learn==1.3.2 scikeras==0.12.0\n",
        "# !pip install scikit-learn scikeras\n",
        "\n",
        "# eventuellement ne pas oublier de relancer le kernel du notebook\n",
        "# !pip install tensorflow==2.17.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAi4CAOIv9_x"
      },
      "outputs": [],
      "source": [
        "# Importation des différentes librairies utiles pour le notebook\n",
        "\n",
        "#Sickit learn met régulièrement à jour des versions et\n",
        "#indique des futurs warnings.\n",
        "#ces deux lignes permettent de ne pas les afficher.\n",
        "import warnings\n",
        "from tensorflow.keras import mixed_precision\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "from sklearn.metrics import classification_report\n",
        "from datetime import datetime\n",
        "# librairies générales\n",
        "import joblib\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from scipy.stats import randint\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "import base64\n",
        "from keras import Input, Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import copy\n",
        "import random\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from scipy.linalg import sqrtm\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "\n",
        "# librairie affichage\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TensorFlow et keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D,UpSampling2D, Dropout, Flatten, BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "from tqdm import tqdm\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
        "import io\n",
        "import tempfile\n",
        "from skimage.feature import hog\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3 # Import InceptionV3\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from tensorflow.keras.applications import ResNet50\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fF5bGlQItqu"
      },
      "source": [
        "##Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkJUBKleItUJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_fid(real_images, generated_images, num_samples=100, batch_size=32):\n",
        "    inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
        "\n",
        "    def preprocess_images(images):\n",
        "        images = tf.image.resize(images, (299, 299))\n",
        "        images = tf.clip_by_value(images, -1.0, 1.0)\n",
        "        images = (images + 1) / 2.0\n",
        "        images = preprocess_input(images * 255.0)\n",
        "        return images\n",
        "\n",
        "    real_images = real_images[:num_samples]\n",
        "    generated_images = generated_images[:num_samples]\n",
        "\n",
        "    real_images = tf.convert_to_tensor(real_images, dtype=tf.float32)\n",
        "    generated_images = tf.convert_to_tensor(generated_images, dtype=tf.float32)\n",
        "\n",
        "    if real_images.shape[0] == 0 or generated_images.shape[0] == 0:\n",
        "        raise ValueError(\"Aucune image valide dans l'échantillon.\")\n",
        "\n",
        "    real_features = inception_model.predict(preprocess_images(real_images), batch_size=batch_size, verbose=0)\n",
        "    generated_features = inception_model.predict(preprocess_images(generated_images), batch_size=batch_size, verbose=0)\n",
        "\n",
        "    if real_features.shape[0] == 0 or generated_features.shape[0] == 0:\n",
        "        raise ValueError(\"Aucune caractéristique extraite, vérifiez les entrées.\")\n",
        "\n",
        "    mu_real = np.mean(real_features, axis=0)\n",
        "    mu_gen = np.mean(generated_features, axis=0)\n",
        "    sigma_real = np.cov(real_features, rowvar=False)\n",
        "    sigma_gen = np.cov(generated_features, rowvar=False)\n",
        "\n",
        "    epsilon = 1e-6\n",
        "    sigma_real += np.eye(sigma_real.shape[0]) * epsilon\n",
        "    sigma_gen += np.eye(sigma_gen.shape[0]) * epsilon\n",
        "\n",
        "    diff = mu_real - mu_gen\n",
        "\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    fid = np.sum(diff**2) + np.trace(sigma_real + sigma_gen - 2 * covmean)\n",
        "    return float(fid) if np.isfinite(fid) else float('inf')\n",
        "\n",
        "def evaluate_gan(generator, real_images, num_samples=100, batch_size=32, save_dir=None, epoch=None):\n",
        "    # Tester avec stddev variable\n",
        "    noise_stddevs = [0.5, 1.0]\n",
        "    for stddev in noise_stddevs:\n",
        "        noise = tf.random.normal([num_samples, 100], mean=0.0, stddev=stddev)\n",
        "        print(f\"Shape du bruit (stddev={stddev}):\", noise.shape)\n",
        "\n",
        "        generated_images = generator(noise, training=False)\n",
        "\n",
        "        real_images = tf.convert_to_tensor(real_images, dtype=tf.float32)\n",
        "        if tf.reduce_min(real_images) < -1.5 or tf.reduce_max(real_images) > 1.5:\n",
        "            print(\"Attention : real_images ne semble pas normalisé à [-1, 1], normalisation appliquée\")\n",
        "            real_images = tf.clip_by_value(real_images, -1.0, 1.0)\n",
        "\n",
        "        print(f\"Generated images min: {tf.reduce_min(generated_images).numpy():.4f}, max: {tf.reduce_max(generated_images).numpy():.4f}\")\n",
        "\n",
        "        try:\n",
        "            fid_score = calculate_fid(real_images, generated_images, num_samples=num_samples, batch_size=batch_size)\n",
        "            print(f\"FID Score (stddev={stddev}): {fid_score:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erreur lors du calcul du FID (stddev={stddev}): {e}\")\n",
        "            fid_score = None\n",
        "\n",
        "        generated_images = tf.clip_by_value((generated_images + 1) / 2.0, 0.0, 1.0)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(min(25, num_samples)):\n",
        "            plt.subplot(5, 5, i+1)\n",
        "            plt.imshow(generated_images[i])\n",
        "            plt.axis('off')\n",
        "        title = f\"Generated Images)\"\n",
        "        plt.suptitle(title, fontsize=12)\n",
        "\n",
        "        if save_dir:\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            save_path = os.path.join(save_dir, f'evaluation_epoch_{epoch if epoch else \"test\"}_stddev_{stddev}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
        "            plt.savefig(save_path)\n",
        "            print(f\"Images sauvegardées à : {save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # Bruit fixe\n",
        "        fixed_noise = tf.random.normal([num_samples, 100], mean=0.0, stddev=stddev, seed=42)\n",
        "        fixed_generated_images = generator(fixed_noise, training=False)\n",
        "        fixed_generated_images = tf.clip_by_value((fixed_generated_images + 1) / 2.0, 0.0, 1.0)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(min(25, num_samples)):\n",
        "            plt.subplot(5, 5, i+1)\n",
        "            plt.imshow(fixed_generated_images[i])\n",
        "            plt.axis('off')\n",
        "        plt.suptitle(f\"Fixed Noise Images (stddev={stddev}, Epoch {epoch if epoch else 'Unknown'})\", fontsize=12)\n",
        "\n",
        "        if save_dir:\n",
        "            fixed_save_path = os.path.join(save_dir, f'fixed_noise_epoch_{epoch if epoch else \"test\"}_stddev_{stddev}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
        "            plt.savefig(fixed_save_path)\n",
        "            print(f\"Images à bruit fixe sauvegardées à : {fixed_save_path}\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_augmented_images(images, datagen, num_examples=5):\n",
        "    images = (images + 1) / 2.0\n",
        "    plt.figure(figsize=(15, 3))\n",
        "    for i in range(num_examples):\n",
        "        # Générer une image augmentée\n",
        "        img = images[i:i+1]  # Batch d'une seule image\n",
        "        aug_iter = datagen.flow(img, batch_size=1)\n",
        "        aug_img = next(aug_iter)[0]\n",
        "        plt.subplot(1, num_examples, i+1)\n",
        "        plt.imshow(aug_img)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def load_images(image_dir, target_size=(64, 64)):\n",
        "    images = []\n",
        "    for filename in os.listdir(image_dir):\n",
        "        img_path = os.path.join(image_dir, filename)\n",
        "        img = Image.open(img_path).resize(target_size)\n",
        "        img = np.array(img) / 127.5 - 1.0  # Normalisation à [-1, 1]\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "def visualize_colorization(grayscale_images, rgb_images, predicted_images, num_examples=5, save_dir=None):\n",
        "    plt.figure(figsize=(15, 5 * num_examples))\n",
        "    for i in range(num_examples):\n",
        "        # Image grayscale\n",
        "        plt.subplot(num_examples, 3, i * 3 + 1)\n",
        "        plt.imshow((grayscale_images[i] + 1) / 2.0, cmap='gray')\n",
        "        plt.title('Grayscale')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Image colorisée\n",
        "        plt.subplot(num_examples, 3, i * 3 + 2)\n",
        "        plt.imshow((predicted_images[i] + 1) / 2.0)\n",
        "        plt.title('Colorized')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Image originale\n",
        "        plt.subplot(num_examples, 3, i * 3 + 3)\n",
        "        plt.imshow((rgb_images[i] + 1) / 2.0)\n",
        "        plt.title('Original')\n",
        "        plt.axis('off')\n",
        "\n",
        "    if save_dir:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        plt.savefig(os.path.join(save_dir, 'colorization_results.png'))\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDJL1KwoJBG2"
      },
      "source": [
        "##Charger les données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75AHELTKwrqw"
      },
      "outputs": [],
      "source": [
        "\n",
        "tiger_dir = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/Data_Project/Tiger-Fox-Elephant/fox'\n",
        "tiger_images = load_images(tiger_dir)\n",
        "my_classes=['fox','Fox_negative_class']\n",
        "\n",
        "#tiger_images = tiger_images[0:4]\n",
        "fox_data = tf.data.Dataset.from_tensor_slices(tiger_images).shuffle(1000).batch(32)\n",
        "print(f\"Nombre d'images chargées : {len(tiger_images)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKjJkG8yPgua"
      },
      "source": [
        "## Data augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5obuX7cPgua"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def augment_dataset(x_train, datagen, augmentation_factor=10):\n",
        "    augmented_images = []\n",
        "    batch_size = 32\n",
        "    x_train_normalized = (x_train + 1) / 2.0\n",
        "\n",
        "    for i in range(len(x_train)):\n",
        "        img = x_train_normalized[i:i+1]\n",
        "        aug_iter = datagen.flow(img, batch_size=1)\n",
        "        for _ in range(augmentation_factor):\n",
        "            aug_img = next(aug_iter)[0]\n",
        "            augmented_images.append(aug_img)\n",
        "\n",
        "    augmented_images = np.array(augmented_images) * 2.0 - 1.0\n",
        "    x_train_augmented = np.concatenate([x_train, augmented_images], axis=0)\n",
        "\n",
        "    return x_train_augmented\n",
        "\n",
        "x_train = load_images(tiger_dir)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "datagen.fit((x_train + 1) / 2.0)\n",
        "plot_augmented_images(x_train, datagen)\n",
        "old_x_train = x_train\n",
        "x_train = augment_dataset(old_x_train, datagen, augmentation_factor=9)\n",
        "\n",
        "print(f\"Taille dataset original : {old_x_train.shape}\")\n",
        "print(f\"Taille dataset augmenté : {x_train.shape}\")\n",
        "#sauvegarder le dataset augmenté pour l'utiliser dans le DCGAN\n",
        "np.save('/content/gdrive/My Drive/Colab Notebooks/ML_FDS/tiger_images_augmented.npy', x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autoencodeurs"
      ],
      "metadata": {
        "id": "gM3pAb-00yQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE=64\n",
        "def load_and_preprocess_images(folder_path, img_size=(64, 64), test_size=0.2):\n",
        "    images = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.png', '.jpg', '.jpeg')):  # Filtrer les formats d'image\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, img_size)\n",
        "                # Normaliser les pixels entre -1 et 1\n",
        "                img = img.astype('float32') / 255\n",
        "                images.append(img)\n",
        "\n",
        "    # Convertir la liste en tableau NumPy\n",
        "    X = np.array(images)\n",
        "\n",
        "    # # Reshape pour ajouter la dimension de canal (comme dans l'exemple Fashion MNIST)\n",
        "    # X = np.reshape(X, (X.shape[0], img_size[0], img_size[1], 3))  # 3 pour RGB\n",
        "\n",
        "    # Diviser en ensembles d'entraînement et de test\n",
        "    X_train, X_test = train_test_split(X, test_size=test_size, random_state=42)\n",
        "\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "folder_path = \"Data_Project/Tiger-Fox-Elephant/fox\"  # Remplace par le chemin réel\n",
        "\n",
        "X_train, X_test = load_and_preprocess_images(folder_path, img_size=(64, 64), test_size=0.2)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "\n",
        "print(f\"X_train min: {X_train.min()}, max: {X_train.max()}\")\n",
        "print(f\"X_test min: {X_test.min()}, max: {X_test.max()}\")\n",
        "\n",
        "\n",
        "\n",
        "def plot_images(images, title, num_images=5):\n",
        "    plt.figure(figsize=(15, 4), dpi=100)\n",
        "    plt.suptitle(title, fontsize=20)\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(images[i], interpolation='nearest')  # Display the image\n",
        "        plt.axis('off')  # Hide axes\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot X_train images\n",
        "plot_images(X_train, \"X_train Images\")\n",
        "\n",
        "# Plot X_test images\n",
        "plot_images(X_test, \"X_test Images\")\n"
      ],
      "metadata": {
        "id": "XePkZtxd01DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille de l'image d'entrée\n",
        "input_shape = (64, 64, 3)\n",
        "# Initialisation du modèle\n",
        "model = Sequential()\n",
        "# Couche d'entrée\n",
        "model.add(Input(shape=input_shape, name=\"Input\"))\n",
        "# Encodeur\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same',name=\"Conv2D_1\"))\n",
        "model.add(MaxPooling2D((2, 2), padding='same', name=\"MaxPooling_1\"))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Conv2D_2\"))\n",
        "model.add(MaxPooling2D((2, 2), padding='same', name=\"MaxPooling_2\"))\n",
        "model.add(Conv2D(4, (3, 3), activation='relu', padding='same', name=\"Conv2D_Bottleneck\"))\n",
        "# Décodeur\n",
        "model.add(Conv2D(4, (3, 3), activation='relu', padding='same',name=\"Conv2D_3\"))\n",
        "model.add(UpSampling2D((2, 2), name=\"UpSampling_1\"))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same',name=\"Conv2D_4\"))\n",
        "model.add(UpSampling2D((2, 2), name=\"UpSampling_2\"))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same',name=\"Conv2D_5\"))\n",
        "\n",
        "# Couche de sortie modifiée pour produire une image 64x64 avec 3 canaux\n",
        "model.add(Conv2D(3, (3, 3), activation='tanh', padding='same', name=\"Output\"))\n",
        "\n",
        "# Compilation du modèle\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='mean_squared_error')\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_yDVSzNb1Eyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 800\n",
        "batch_size = 32\n",
        "model_filename = 'AutoEncoderMnist.keras'\n",
        "# Callback pour sauvegarder le modèle toutes les époques\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "\"autoencoder_fashionmnist_epoch{epoch:02d}.keras\", # Nom du fichier\n",
        "save_freq='epoch',\n",
        "save_weights_only=False,\n",
        "verbose=1\n",
        ")\n",
        "# Entraînement du modèle\n",
        "history = model.fit(\n",
        "X_train, X_train,\n",
        "epochs=epochs,\n",
        "batch_size=batch_size,\n",
        "validation_data=(X_test, X_test),\n",
        "verbose=1,\n",
        "callbacks=[checkpoint_callback]\n",
        ")\n",
        "model.save(model_filename)\n",
        "print(f'Modèle sauvegardé sous le nom : {model_filename}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EN5iyZ6K2Ugl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = 'AutoEncoderMnist.keras'\n",
        "model = load_model(model_filename)\n",
        "\n",
        "# Prédiction avec le modèle\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "# Affichage des images d'entrée\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
        "fig.suptitle(\"Images Entrée\", fontsize=20)\n",
        "for i in range(5):\n",
        "    axes[i].imshow(X_test[i], interpolation='nearest')\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(len(pred))\n",
        "# Affichage des images de sortie (prédictions)\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 4))\n",
        "fig.suptitle(\"Images Sortie\", fontsize=20)\n",
        "for i in range(5):\n",
        "    axes[i].imshow(pred[i] , cmap='gray' ,interpolation='nearest')\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k1zE4oB626_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Autoencodeurs bruité"
      ],
      "metadata": {
        "id": "jbKkQutJ6zrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition du facteur de bruit\n",
        "noise_factor = 0.3\n",
        "# Ajout du bruit aux images d'entraînement et de test\n",
        "X_train_noisy = X_train + noise_factor * np.random.normal(loc=0.0,scale=1.0, size=X_train.shape)\n",
        "X_test_noisy = X_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
        "# Limitation des valeurs des images bruitées entre 0 et 1\n",
        "X_train_noisy = np.clip(X_train_noisy, 0., 1.)\n",
        "X_test_noisy = np.clip(X_test_noisy, 0., 1.)\n",
        "# Affichage des images bruitées\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(5): # Afficher 5 images\n",
        "  ax = plt.subplot(1, 5, i + 1)\n",
        "  plt.imshow(X_test_noisy[i], cmap='gray')\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TPLcXpAZ1RS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taille de l'image d'entrée\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "# Initialisation du modèle\n",
        "model = keras.Sequential(name=\"denoising_autoencoder\")\n",
        "\n",
        "# Encodeur\n",
        "model.add(layers.Input(shape=input_shape, name=\"Input\"))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name=\"Conv2D_1\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding='same', name=\"MaxPooling_1\"))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Conv2D_2\"))\n",
        "model.add(layers.MaxPooling2D((2, 2), padding='same', name=\"MaxPooling_2\"))\n",
        "model.add(layers.Conv2D(4, (3, 3), activation='relu', padding='same', name=\"Conv2D_Bottleneck\"))  # Bottleneck\n",
        "\n",
        "# Décodeur\n",
        "model.add(layers.Conv2D(4, (3, 3), activation='relu', padding='same', name=\"Conv2D_3\"))\n",
        "model.add(layers.UpSampling2D((2, 2), name=\"UpSampling_1\"))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', name=\"Conv2D_4\"))\n",
        "model.add(layers.UpSampling2D((2, 2), name=\"UpSampling_2\"))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', name=\"Conv2D_5\"))\n",
        "\n",
        "# Couche de sortie (pour la reconstruction de l'image)\n",
        "model.add(layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same', name=\"Output\"))  # Sigmoid for [0, 1] output\n",
        "\n",
        "# Compilation du modèle\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt, loss='mse')  # MSE loss for image reconstruction\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "cPkQT18d-kZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "model_filename = 'AutoEncoderNoise.keras'\n",
        "# Callback pour sauvegarder le modèle toutes les époques\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "\"autoencoder_noise_fashionmnist_epoch{epoch:02d}.keras\",\n",
        "save_freq='epoch',\n",
        "save_weights_only=False,\n",
        "verbose=1\n",
        ")\n",
        "# Entraînement du modèle\n",
        "history = model.fit(\n",
        "X_train_noisy, X_train,\n",
        "epochs=epochs,\n",
        "batch_size=batch_size,\n",
        "validation_data=(X_test_noisy, X_test),\n",
        "verbose=1,\n",
        "callbacks=[checkpoint_callback]\n",
        ")\n",
        "#Sauvegarde du modèle\n",
        "model.save(model_filename)\n",
        "print(f'Modèle sauvegardé sous le nom : {model_filename}')"
      ],
      "metadata": {
        "id": "eeQ_8cc01S3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = 'AutoEncoderNoise.keras'\n",
        "model = load_model(model_filename)\n",
        "\n",
        "# Prédiction sur les images bruitées\n",
        "pred = model.predict(X_test_noisy)\n",
        "# Affichage des images bruitées\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.suptitle(\"Images bruitées\", fontsize=20)\n",
        "for i in range(5):\n",
        "  ax = plt.subplot(2, 5, i + 1)\n",
        "  plt.imshow(X_test_noisy[i], cmap='gray')\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# Affichage des images de sortie après débruitage\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.suptitle(\"Images débruitées\", fontsize=20)\n",
        "for i in range(5):\n",
        "  ax = plt.subplot(2, 5, i + 1)\n",
        "  plt.imshow(pred[i], cmap='gray')\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RrifeOD965bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVaa3QzPWvtS"
      },
      "source": [
        "#Modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCZPmnE4HU1s"
      },
      "outputs": [],
      "source": [
        "#Les variables globales\n",
        "epochs=600\n",
        "taille_backup=100 # le nombre d'epochs après les quelles on fait backup des images et on les stocke\n",
        "IMAGE_SIZE = 32\n",
        "\n",
        "batch_size = 32\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH6a4WuXwdfx"
      },
      "outputs": [],
      "source": [
        "nameFile = f'generator_epoch_'\n",
        "\n",
        "def build_generator():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(4*4*256, input_dim=100))\n",
        "    model.add(layers.Reshape((4, 4, 256)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, 4, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, 4, strides=2, padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(3, 4, strides=4, padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(64, 4, strides=2, padding='same', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(128, 4, strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(256, 4, strides=2, padding='same'))\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([tf.shape(images)[0], 100])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input, save_dir):\n",
        "    predictions = model(test_input, training=False)\n",
        "    predictions = (predictions + 1) / 2.0\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png'))\n",
        "    plt.close()\n",
        "\n",
        "def train_gan(dataset, epochs, save_dir):\n",
        "    global nameFile  # Déclarer nameFile comme globale\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    test_noise = tf.random.normal([16, 100])\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "\n",
        "        if (epoch + 1) % 3 == 0:\n",
        "            nameFile = f'generator_epoch_{epoch+1}_{datetime.now()}.h5'\n",
        "            print(nameFile)\n",
        "            generate_and_save_images(generator, epoch + 1, test_noise, save_dir)\n",
        "            keras.saving.save_model(generator,os.path.join(save_dir, nameFile))\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Time: {time.time() - start:.2f}s, Gen Loss: {gen_loss:.4f}, Disc Loss: {disc_loss:.4f}\")\n",
        "#dataset augmented\n",
        "# dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000).batch(batch_size)\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/gan_outputs'\n",
        "train_gan(dataset, epochs=epochs, save_dir=save_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tPCAHNb_weey"
      },
      "outputs": [],
      "source": [
        "\n",
        "save_dir = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/gan_outputs'\n",
        "generator = load_model(os.path.join(save_dir, nameFile))\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "generator.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n",
        "\n",
        "tiger_images = np.load('/content/gdrive/My Drive/Colab Notebooks/ML_FDS/tiger_images_augmented.npy')\n",
        "tiger_images = tf.convert_to_tensor(tiger_images, dtype=tf.float32)\n",
        "evaluate_gan(generator, tiger_images, num_samples=100, batch_size=32, save_dir=save_dir, epoch=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkY_mjzVpjSd"
      },
      "outputs": [],
      "source": [
        "nameFile = \"generator_epoch_300_20250506_220726.h5\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTGYHDNApGiW"
      },
      "source": [
        "#Colorisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcMF8CkfpHz8"
      },
      "outputs": [],
      "source": [
        "epochs_colorization=40\n",
        "batch_size_colorization= 32\n",
        "def rgb_to_grayscale(images):\n",
        "    images = (images + 1) / 2.0\n",
        "    grayscale = tf.image.rgb_to_grayscale(images)\n",
        "    grayscale = grayscale * 2.0 - 1.0\n",
        "    return grayscale.numpy()\n",
        "\n",
        "def prepare_colorization_dataset(image_path):\n",
        "    rgb_images = np.load(image_path)\n",
        "    grayscale_images = rgb_to_grayscale(rgb_images)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((grayscale_images, rgb_images))\n",
        "    dataset = dataset.shuffle(1000).batch(32)\n",
        "    return dataset, grayscale_images, rgb_images\n",
        "\n",
        "def build_colorization_model():\n",
        "    inputs = tf.keras.Input(shape=(64, 64, 1))\n",
        "\n",
        "    # Encodeur\n",
        "    e1 = layers.Conv2D(64, 4, strides=2, padding='same', activation='relu')(inputs)\n",
        "    e2 = layers.Conv2D(128, 4, strides=2, padding='same', activation='relu')(e1)\n",
        "    e3 = layers.Conv2D(256, 4, strides=2, padding='same', activation='relu')(e2)\n",
        "    e4 = layers.Conv2D(512, 4, strides=2, padding='same', activation='relu')(e3)\n",
        "    # Décodeur\n",
        "    d1 = layers.Conv2DTranspose(256, 4, strides=2, padding='same', activation='relu')(e4)\n",
        "    d1 = layers.Concatenate()([d1, e3])  # Skip connection\n",
        "    d2 = layers.Conv2DTranspose(128, 4, strides=2, padding='same', activation='relu')(d1)\n",
        "    d2 = layers.Concatenate()([d2, e2])\n",
        "    d3 = layers.Conv2DTranspose(64, 4, strides=2, padding='same', activation='relu')(d2)\n",
        "    d3 = layers.Concatenate()([d3, e1])\n",
        "\n",
        "    outputs = layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(d3)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_colorization(image_path, epochs=50, batch_size=32):\n",
        "    dataset, grayscale_images, rgb_images = prepare_colorization_dataset(image_path)\n",
        "\n",
        "    model = build_colorization_model()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    save_dir = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/colorization_models'\n",
        "    file_name=f'generator_epoch_{datetime.now()}'\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        os.path.join(save_dir, file_name),\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        dataset,\n",
        "        epochs=epochs,\n",
        "        callbacks=[checkpoint, early_stopping]\n",
        "    )\n",
        "\n",
        "    num_examples = 5\n",
        "    test_grayscale = grayscale_images[:num_examples]\n",
        "    predicted_rgb = model.predict(test_grayscale)\n",
        "\n",
        "    vis_save_dir = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/colorization_results'\n",
        "    visualize_colorization(test_grayscale, rgb_images[:num_examples], predicted_rgb,\n",
        "                         num_examples=num_examples, save_dir=vis_save_dir)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "image_path = '/content/gdrive/My Drive/Colab Notebooks/ML_FDS/tiger_images_augmented.npy'\n",
        "\n",
        "colorization_model, training_history = train_and_evaluate_colorization(image_path, epochs=epochs_colorization, batch_size=batch_size_colorization)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XevyK73LWpS3"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNftjd+S1TH2ELR/L3XoaZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}